{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4904c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8f9db0",
   "metadata": {},
   "source": [
    "**YOLO (You only look once)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45809b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# یولو یه الگوریتم دیپ لرنینگه که برای تشخیص اشیا، جدا کردن آبجکت از تصویر، کلاسبندی، تشخیص نقاط کلیدی بدن انسان و دنبال کردن آبجکت در تصاویر و ویدیو ها استفاده میشه\n",
    "# یولو 8 تا ورژن داره که جدید ترین و بهترینش وی8 هست ولی مشکلش اینه که به پردازش بالاتری نیاز داره\n",
    "# یولو8 در اندازه های مختلفی طراحی شده که هر چی بزرگتر میشه پیچیده تر میشه ولی پردازش بیشتری هم نیاز داره\n",
    "# باید با توجه به پروژه بهترین نوع انتخاب بشه\n",
    "# : به ترتیب از کوچیک به بزرگ\n",
    "# nano, small, medium, large, x-large\n",
    "# حرف اول هر کدوم رو بعد از یولو وی8 موقع لود بنویسیم همون دانلود میشه\n",
    "# تصاویر درست شده توسط یولو توی یه فولدر به اسم رانز ذخیره میشن\n",
    "# به عنوان سورس ورودی مدل یولو، علاوه بر عکس و ویدیو میتونیم لینک یوتیوب و... هم بدیم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3285ad",
   "metadata": {},
   "source": [
    "**Detection in image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5851ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تشخیص آبجکت های یک تصویر\n",
    "# دور آبجکت یه مستطیل میکشه و اسم آبجکت و درصد تعلق به کلاس انتخاب شده رو هم نشون میده\n",
    "# کلا 80 تا کلاس رو تشخیص میده که شامل اشیا مختلفی مثل ماشین، آدم، حیوانات و... هستن\n",
    "\n",
    "# لود کردن مدل مخصوص دیتکشن یولو با اندازه نانو\n",
    "detection_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# save=True : ذخیره کردن عکس\n",
    "# conf=0.6 : فقط کانفیدنس های بالای 60 درصد رو در نظر بگیر\n",
    "# save_txt=True : اطلاعات آبجکت هارو توی یه فایل تکست ذخیره کن\n",
    "# اول کلاس آبجکت که یکی از 80 تاست. بعد اندازه مستطیل دور آبجکت که به صورت نرمالایز هست\n",
    "# save_conf=True : کانفیدنس هارو هم توی فایل تکست بنویس در آخر\n",
    "results = detection_model('./images/bicycles.jpg', save=True, conf=0.6, save_txt=True, save_conf=True)\n",
    "\n",
    "# نمایش تصویر خروجی\n",
    "predicted_objects_image = cv2.imread('./runs/detect/predict/bicycles.jpg')\n",
    "\n",
    "cv2.imshow('Predicted objects image', predicted_objects_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c88990",
   "metadata": {},
   "source": [
    "**Detection in video**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b43131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# تشخیص آبجکت های یک ویدیو\n",
    "\n",
    "detection_model = YOLO('yolov8n.pt')\n",
    "\n",
    "# save_frames=True : تمام فریم هارو ذخیره کن\n",
    "# stream=True : به‌ جای پردازش کل ویدیو یه‌جا (که سنگین و کند می‌شه)، مدل رو توی حالت استریم قرار میده. این یعنی فریم‌ها یکی یکی با ژنراتور پردازش میشن که باعث میشه حافظه کمتری مصرف بشه\n",
    "result_frames = detection_model('./videos/dashcam.mp4', save=True, save_frames=True, stream=True)\n",
    "\n",
    "# چون از استریم استفاده کردیم، فریم ها یکی یکی میان و ما باید هر بار فریم پردازش شده رو بگیریم\n",
    "for frame in result_frames:\n",
    "    pass\n",
    "\n",
    "# نمایش ویدیو\n",
    "result_video = cv2.VideoCapture('./runs/detect/predict2/dashcam.avi')\n",
    "\n",
    "if not result_video.isOpened():\n",
    "    print('Sorry, the video was not opened.')\n",
    "\n",
    "while result_video.isOpened():\n",
    "    ret, frame = result_video.read()\n",
    "\n",
    "    if ret:\n",
    "        cv2.imshow('result_video', frame)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        result_video.release()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71283d0",
   "metadata": {},
   "source": [
    "**Segmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68578f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\images\\bicycles.jpg: 480x640 4 persons, 2 bicycles, 283.3ms\n",
      "Speed: 6.7ms preprocess, 283.3ms inference, 26.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "[[      147.2       529.2]\n",
      " [      147.2         502]\n",
      " [      145.6       500.4]\n",
      " ...\n",
      " [      156.8       519.6]\n",
      " [      156.8         526]\n",
      " [      150.4       532.4]]\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# جدا کردن آبجکت از تصویر\n",
    "\n",
    "# لود کردن مدل مخصوص سگمنتیشن\n",
    "segmentation_model = YOLO('yolov8n-seg.pt')\n",
    "\n",
    "results = segmentation_model('./images/bicycles.jpg', save=True)\n",
    "\n",
    "# نمایش\n",
    "semented_objects_image = cv2.imread('./runs/segment/predict/bicycles.jpg')\n",
    "\n",
    "cv2.imshow('Segmented objects image', semented_objects_image)\n",
    "# نمایش ماسک ها\n",
    "\n",
    "# اول برای درک بهتر ایکس و وای ها یا همون مختصات ماسک رو نشون میدیم\n",
    "# results[0] : چون مشخصات داخل یه لیستن و ما عنصر اولشو میخوایم\n",
    "# xy[0] : ماسک آبجکت سگمنت شده ااول\n",
    "print(results[0].masks.xy[0])\n",
    "\n",
    "# نمایش خود ماسک\n",
    "mask = results[0].masks.data[0]\n",
    "print(mask)\n",
    "# حالا باید ماسک رو به یه آرایه تبدیل کنیم چون تصویر یه آرایست نه لیست\n",
    "mask = mask.numpy()\n",
    "\n",
    "# الان میخوایم آبجکت رو روی ماسک نشون بدیم\n",
    "# اول ماسک رو هم سایز تصویرمون میکنیم\n",
    "image = cv2.imread('./images/bicycles.jpg')\n",
    "resized_mask = np.uint8(cv2.resize(mask, (image.shape[1], image.shape[0]))) # نوع داده ماسک باید حتما یواینت8 باشه\n",
    "\n",
    "# بعد با عملگر اند آبجکت رو روی ماسک میندازیم\n",
    "object_segmented_image = cv2.bitwise_and(image, image, mask=resized_mask)\n",
    "\n",
    "# نمایش\n",
    "cv2.imshow('Original', image)\n",
    "cv2.imshow('Mask of first object', mask)\n",
    "cv2.imshow('First object segmented image', object_segmented_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5456332",
   "metadata": {},
   "source": [
    "**Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa7d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\images\\dog.jpeg: 224x224 German_shepherd 0.94, malinois 0.02, keeshond 0.02, groenendael 0.01, Australian_terrier 0.00, 29.5ms\n",
      "Speed: 5.3ms preprocess, 29.5ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
      "Index of the best confidenced class: 235 | Name of the class: German_shepherd\n"
     ]
    }
   ],
   "source": [
    "# کلاسیندی آبجکت های توی تصویر\n",
    "# توی کلسیفیکیشن یولو، ما 1000 تا کلاس داریم به جای 80 تا\n",
    "# اینطوریه که آبجکت اصلی تصویر تشحیص داده میشه و بعد 5 تا کلاسی که بیشترین کانفیدنس رو دارن نمایش داده میشن\n",
    "\n",
    "classification_model = YOLO('yolov8n-cls.pt')\n",
    "\n",
    "result = classification_model('./images/dog.jpeg', save=True)\n",
    "\n",
    "# نمایش\n",
    "classified_object_image = cv2.imread('./runs/classify/predict/dog.jpg')\n",
    "\n",
    "cv2.imshow('Classified object image', classified_object_image)\n",
    "\n",
    "# تشخیص کلاس با بیشترین کانفیدنس\n",
    "best_confidence_index = result[0].probs.top1\n",
    "best_confidence_name = result[0].names[best_confidence_index]\n",
    "print(f'Index of the best confidenced class: {best_confidence_index} | Name of the class: {best_confidence_name}')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a84725",
   "metadata": {},
   "source": [
    "**Pose estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7f2a6485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\images\\people.webp: 640x640 3 persons, 320.9ms\n",
      "Speed: 15.2ms preprocess, 320.9ms inference, 4.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "torch.Size([3, 17, 2])\n",
      "[[[     625.76      91.293]\n",
      "  [     639.82      77.528]\n",
      "  [     613.46      77.866]\n",
      "  [     665.64      80.512]\n",
      "  [     600.06      81.999]\n",
      "  [     714.33      160.08]\n",
      "  [      576.9      154.51]\n",
      "  [     771.34      251.93]\n",
      "  [     532.94      251.72]\n",
      "  [     739.54       278.1]\n",
      "  [     522.37       343.4]\n",
      "  [     687.53      377.24]\n",
      "  [     596.91      368.95]\n",
      "  [     680.07      542.51]\n",
      "  [     563.89      532.81]\n",
      "  [     667.58      682.02]\n",
      "  [     546.96      682.28]]\n",
      "\n",
      " [[     405.95      97.065]\n",
      "  [     418.74      83.567]\n",
      "  [      393.2      84.252]\n",
      "  [     437.74      87.904]\n",
      "  [     375.43      90.073]\n",
      "  [     468.52      171.64]\n",
      "  [      339.7      161.39]\n",
      "  [     475.66      276.56]\n",
      "  [     306.79      236.86]\n",
      "  [     391.49      313.46]\n",
      "  [     344.25      289.15]\n",
      "  [      431.9       382.7]\n",
      "  [     345.05       377.5]\n",
      "  [     443.55       539.7]\n",
      "  [     345.24      535.14]\n",
      "  [     444.84       670.1]\n",
      "  [     349.67      669.37]]\n",
      "\n",
      " [[     147.39      81.114]\n",
      "  [     160.74      67.168]\n",
      "  [     132.06      67.612]\n",
      "  [     175.77      75.615]\n",
      "  [     104.38      76.068]\n",
      "  [     205.88      154.98]\n",
      "  [     82.088      163.56]\n",
      "  [     243.09       252.4]\n",
      "  [      107.7       277.3]\n",
      "  [     186.91      233.71]\n",
      "  [     194.85      266.41]\n",
      "  [     194.47      383.35]\n",
      "  [     109.51      386.97]\n",
      "  [     171.46      546.37]\n",
      "  [     88.333      561.67]\n",
      "  [     149.04         695]\n",
      "  [     96.389      718.35]]]\n"
     ]
    }
   ],
   "source": [
    "# تشخیص نقاط کلیدی بدن انسان توی تصویر\n",
    "# هفده تا نقطه کلیدی تشخیص داده میشن که اگه یه وجود نداشته باشه یا خارج از تصویر باشه مقدار غایب بهش تعلق میگیره\n",
    "\n",
    "pose_estimation_model = YOLO('yolov8n-pose')\n",
    "\n",
    "results = pose_estimation_model('./images/people.webp', save=False)\n",
    "\n",
    "# شیپ نقاط کلیدی\n",
    "print(results[0].keypoints.xy.shape) # اولی تعداد انسان ها، بعدش تعداد نقاط کلیدی که همیشه 17 تاست و بعدم مختصات نقطه\n",
    "# نمایش مختصات نقاط کلیدی\n",
    "key_points = results[0].keypoints.xy.numpy()\n",
    "print(key_points)\n",
    "\n",
    "# نمایش\n",
    "people_pose_estimated_image = cv2.imread('./runs/pose/predict/people.jpg')\n",
    "\n",
    "# cv2.imshow('People pose estimated image', people_pose_estimated_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57949a1",
   "metadata": {},
   "source": [
    "**Tracking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "21009ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 302.4ms\n",
      "video 1/1 (frame 2/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 320.3ms\n",
      "video 1/1 (frame 3/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 219.4ms\n",
      "video 1/1 (frame 4/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 158.8ms\n",
      "video 1/1 (frame 5/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 149.6ms\n",
      "video 1/1 (frame 6/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 158.2ms\n",
      "video 1/1 (frame 7/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 172.9ms\n",
      "video 1/1 (frame 8/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 159.8ms\n",
      "video 1/1 (frame 9/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 165.3ms\n",
      "video 1/1 (frame 10/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 138.3ms\n",
      "video 1/1 (frame 11/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 160.3ms\n",
      "video 1/1 (frame 12/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 1 car, 1 truck, 187.2ms\n",
      "video 1/1 (frame 13/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 157.2ms\n",
      "video 1/1 (frame 14/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 154.1ms\n",
      "video 1/1 (frame 15/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 142.7ms\n",
      "video 1/1 (frame 16/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 173.7ms\n",
      "video 1/1 (frame 17/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 148.4ms\n",
      "video 1/1 (frame 18/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 149.0ms\n",
      "video 1/1 (frame 19/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 147.1ms\n",
      "video 1/1 (frame 20/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 159.1ms\n",
      "video 1/1 (frame 21/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 183.2ms\n",
      "video 1/1 (frame 22/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 179.7ms\n",
      "video 1/1 (frame 23/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 181.7ms\n",
      "video 1/1 (frame 24/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 4 cars, 137.1ms\n",
      "video 1/1 (frame 25/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 4 cars, 144.1ms\n",
      "video 1/1 (frame 26/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 4 cars, 146.2ms\n",
      "video 1/1 (frame 27/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 4 cars, 142.3ms\n",
      "video 1/1 (frame 28/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 141.3ms\n",
      "video 1/1 (frame 29/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 137.8ms\n",
      "video 1/1 (frame 30/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 164.8ms\n",
      "video 1/1 (frame 31/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 4 cars, 152.9ms\n",
      "video 1/1 (frame 32/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 139.1ms\n",
      "video 1/1 (frame 33/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 148.4ms\n",
      "video 1/1 (frame 34/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 3 cars, 1 truck, 141.6ms\n",
      "video 1/1 (frame 35/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 143.8ms\n",
      "video 1/1 (frame 36/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 142.8ms\n",
      "video 1/1 (frame 37/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 142.2ms\n",
      "video 1/1 (frame 38/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 163.3ms\n",
      "video 1/1 (frame 39/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 163.5ms\n",
      "video 1/1 (frame 40/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 191.3ms\n",
      "video 1/1 (frame 41/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 153.7ms\n",
      "video 1/1 (frame 42/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 149.0ms\n",
      "video 1/1 (frame 43/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 148.6ms\n",
      "video 1/1 (frame 44/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 136.1ms\n",
      "video 1/1 (frame 45/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 138.9ms\n",
      "video 1/1 (frame 46/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 142.5ms\n",
      "video 1/1 (frame 47/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 147.4ms\n",
      "video 1/1 (frame 48/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 161.6ms\n",
      "video 1/1 (frame 49/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 148.3ms\n",
      "video 1/1 (frame 50/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 162.0ms\n",
      "video 1/1 (frame 51/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 147.0ms\n",
      "video 1/1 (frame 52/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 162.3ms\n",
      "video 1/1 (frame 53/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 132.2ms\n",
      "video 1/1 (frame 54/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 147.7ms\n",
      "video 1/1 (frame 55/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 145.9ms\n",
      "video 1/1 (frame 56/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 138.2ms\n",
      "video 1/1 (frame 57/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 146.4ms\n",
      "video 1/1 (frame 58/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 1 truck, 150.3ms\n",
      "video 1/1 (frame 59/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 149.9ms\n",
      "video 1/1 (frame 60/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 157.0ms\n",
      "video 1/1 (frame 61/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 169.8ms\n",
      "video 1/1 (frame 62/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 143.9ms\n",
      "video 1/1 (frame 63/63) c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\videos\\dashcam.mp4: 384x640 2 cars, 2 trucks, 144.2ms\n",
      "Speed: 4.7ms preprocess, 159.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\track\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# دنبال کردن آجکت ها توی ویدیو\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# show=True : همزمان با پردازش فریم ها اونارو نمایش هم بده\n",
    "# persist=True : یعنی به هر آبجکت یه آیدی مخصوص بده و اون رو تو حافظه نگه دار تا اگه اون آبجکت دوباره تو ویدیو ظاهر شد بفهمی همونه\n",
    "# اگه فالس بدیم آیدی توی حافظه ذخیره نمیشه و تغییر میکنه\n",
    "result_frames = model.track('./videos/dashcam.mp4', save=True, show=True, persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165c33d",
   "metadata": {},
   "source": [
    "**Fine-Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f80c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\Abolfazl\\Desktop\\computer\\programming\\machine_learning\\computer_vision\\yolo\\datasets\\solar_panels_detection\\test\\images\\DJI_0753_MP4-28_jpg.rf.33506bc0ca65dd9508a746ae3e514942.jpg: 384x640 3 solar-panelss, 144.8ms\n",
      "Speed: 7.9ms preprocess, 144.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# استفاده از دیتاست متفرقه برای تشخیص یا کلاسبندی یه آبجکت خاص\n",
    "# از اونجایی که کلاس های دیتکشن کلا 80تاست و ما اغلب اوقات به کلاس های بیشتری نیاز داریم، میتونیم از دیتاست های جدا برای ترین یولو و استفاده ازش استفاده کنیم\n",
    "# دلیل اینکه یولو به طور دیفالت کلا 80 تا برای دیتکشن داره اینه که دیتکشن نیاز به داده های پیچیده مثل کادر و... داره\n",
    "# دیتکشن باید بهمون بگه توی تصویر چیا هست و هرچی کجاست؟\n",
    "# ولی کلسیفیکیشن فقط میگه تصویر در مورد چیه؟ یه دونه چی توی تصویر هست؟ به خاطر همین ساده تره و 1000 تا کلاس داره\n",
    "\n",
    "# ترین کردن دیتاست روی یولو\n",
    "model = YOLO('yolov8n.pt')\n",
    "# imgsz=640 : تصاویر قبل از ورود به مدل ریسایز میشن\n",
    "fine_tuning = model.train(data='./datasets/solar_panels_detection/data.yaml', epochs=20, batch=8, device='cpu', imgsz=640)\n",
    "\n",
    "# استفاده از مدل ترین شده\n",
    "solar_panels_detection_model = YOLO('./runs/detect/train/weights/best.pt')\n",
    "result = solar_panels_detection_model('./datasets/solar_panels_detection/test/images/DJI_0753_MP4-28_jpg.rf.33506bc0ca65dd9508a746ae3e514942.jpg', save=True)\n",
    "\n",
    "# نمایش\n",
    "solar_panels_detected = cv2.imread('./runs/detect/predict3/DJI_0753_MP4-28_jpg.rf.33506bc0ca65dd9508a746ae3e514942.jpg')\n",
    "solar_panels_detected = cv2.resize(solar_panels_detected, (0, 0), fx=0.4, fy=0.4)\n",
    "\n",
    "cv2.imshow('Solar panels detected', solar_panels_detected)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
